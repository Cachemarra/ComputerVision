{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the digit recognition model\n",
    "\n",
    "We will use MNIST dataset for training as we only need 0-9 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Libraries\n",
    "from Configurations.models.sudokunet import SudokuNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set the hyperparameters and load the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading MNIST dataset...\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "INIT_LR = 1e-3 # Learning Rate\n",
    "EPOCHS = 10 # Number of epochs\n",
    "BS = 32 # Batch size\n",
    "\n",
    "# Load the MNIST dataset\n",
    "print(\"[INFO] Loading MNIST dataset...\")\n",
    "((trainX, trainY), (testX, testY)) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST preprocessing\n",
    "\n",
    "MNIST data comes as numpy arrays [28, 28]. \n",
    "We're going to: \n",
    "- format the data as batches with a new dimention to indicate is a grayscale image, \n",
    "- Normalize the values (i. e. dividing by /255.0)\n",
    "- Finally, convert the labels from integers to vectors.\n",
    "\n",
    "What the last step do is changing the encode from [1, 3, 2, 0] to ``[[0, 1, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0]]``\n",
    "\n",
    "This is called One-Hot encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the grayscale channel\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "# Size of trainX = (60000, 28, 28, 1)\n",
    "\n",
    "# Normalizing\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    "\n",
    "# Convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.fit_transform(testY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the model\n",
    "\n",
    "We load the SudokuNet and then compile it with our desire parameters.\n",
    "The optimizer will be Adam and the loss will be Categorical Cross Entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compiling the model...\n",
      "[INFO] Compiling Model\n"
     ]
    }
   ],
   "source": [
    "#%% Initializing the model\n",
    "print(\"[INFO] Compiling the model...\")\n",
    "opt = Adam(lr=INIT_LR)\n",
    "model = SudokuNet.build(width=28, height=28, depth=1, classes=10)\n",
    "\n",
    "print(\"[INFO] Compiling Model\")\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"mse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We start the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 22s 6ms/step - loss: 0.9120 - accuracy: 0.6856 - mse: 0.0398 - val_loss: 0.0796 - val_accuracy: 0.9773 - val_mse: 0.0035\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2436 - accuracy: 0.9260 - mse: 0.0112 - val_loss: 0.0613 - val_accuracy: 0.9825 - val_mse: 0.0027\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1815 - accuracy: 0.9466 - mse: 0.0082 - val_loss: 0.0398 - val_accuracy: 0.9883 - val_mse: 0.0019\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1470 - accuracy: 0.9564 - mse: 0.0066 - val_loss: 0.0405 - val_accuracy: 0.9878 - val_mse: 0.0019\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1283 - accuracy: 0.9613 - mse: 0.0058 - val_loss: 0.0351 - val_accuracy: 0.9898 - val_mse: 0.0016\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1190 - accuracy: 0.9657 - mse: 0.0053 - val_loss: 0.0338 - val_accuracy: 0.9901 - val_mse: 0.0015\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1074 - accuracy: 0.9674 - mse: 0.0050 - val_loss: 0.0330 - val_accuracy: 0.9903 - val_mse: 0.0015\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1017 - accuracy: 0.9684 - mse: 0.0047 - val_loss: 0.0316 - val_accuracy: 0.9906 - val_mse: 0.0014\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0931 - accuracy: 0.9723 - mse: 0.0042 - val_loss: 0.0317 - val_accuracy: 0.9900 - val_mse: 0.0015\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0934 - accuracy: 0.9719 - mse: 0.0043 - val_loss: 0.0269 - val_accuracy: 0.9924 - val_mse: 0.0012\n"
     ]
    }
   ],
   "source": [
    "#%% Training the model\n",
    "\n",
    "history = model.fit(\n",
    "    trainX, trainY, \n",
    "    validation_data=(testX, testY),\n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BS, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the model\n",
    "\n",
    "Then we show the evaluations of our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating the model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       1.00      1.00      1.00      1135\n",
      "           2       0.99      1.00      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       1.00      0.99      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       1.00      0.99      0.99       958\n",
      "           7       0.99      0.99      0.99      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.99      0.99      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "[INFO] Saving the model...\n"
     ]
    }
   ],
   "source": [
    "#%% Model evaluation\n",
    "print(\"[INFO] Evaluating the model...\")\n",
    "predictions = model.predict(testX)\n",
    "print(\n",
    "    classification_report(\n",
    "        testY.argmax(axis=1), \n",
    "        predictions.argmax(axis=1), \n",
    "        target_names=[str(x) for x in lb.classes_]\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Serializing the model to disk\n",
    "print(\"[INFO] Saving the model...\")\n",
    "model.save(\"./Configurations/models/sudokunet.h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c21e2ad06d3fae75f452f0ce83f813ba84392946366d7202f73a50514fe02fdb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
